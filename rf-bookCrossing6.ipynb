{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# BibRec: Re-Training Random Forest Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Features: Country, State, Age, Year-of-Publication, Publisher"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Dev/repos/FH-SBG/MMT1/RES/recommender-systems/wt-rf/bibrec/server/data_exploration.py:6: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  books = pd.read_csv(path, sep=\";\", encoding=\"latin-1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With NaN values 34.862889904962536\n",
      "used mean values 34.89615301832869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Dev/repos/FH-SBG/MMT1/RES/recommender-systems/wt-rf/bibrec/server/data_exploration.py:37: FutureWarning: In a future version of pandas all arguments of StringMethods.split except for the argument 'pat' will be keyword-only.\n",
      "  location_seperated = users.location.str.split(',', 2, expand=True)\n"
     ]
    }
   ],
   "source": [
    "from bibrec.server.data_exploration import get_normalized_data, hot_encode_country\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "books, users, ratings = get_normalized_data(books_path='data/BX-Books.csv', users_path='data/BX-Users.csv', ratings_path='data/BX-Book-Ratings.csv')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# limit data volume\n",
    "df_ratings = ratings.groupby('isbn13').user_id.count().sort_values(ascending=False)\n",
    "df_ratings = ratings[1000:2000]\n",
    "df_ratings = df_ratings.reset_index()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# RF Features: Country, State, Age, Year-of-Publication, Publisher\n",
    "tmp_users = users.filter(regex=\"user_id|age|country_|state_\", axis=1)\n",
    "tmp_books = books.filter(regex=\"isbn13|normalized_year_of_publication|publisher_\", axis=1)\n",
    "# df = df_ratings.filter(regex=\"isbn13|user_id|normalized_rating\", axis=1)\n",
    "df = df_ratings.filter(regex=\"isbn13|user_id|book_rating\", axis=1)\n",
    "df = df.merge(tmp_users)\n",
    "df = df.merge(tmp_books)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "     index  user_id        isbn  book_rating         isbn13        age  \\\n0     1000   277784  0440802911            8   978044080297  17.000000   \n1     1001   277788  0440407524            8  9780440407522  17.000000   \n2     1002   277794  0440967694            8  9780440967699  47.843881   \n3     1003   277795  0064406601            5  9780064406604  17.000000   \n4     1004   277797  0440228441            8  9780440228448  17.000000   \n..     ...      ...         ...          ...            ...        ...   \n995   1995   278663  0451182014            3  9780451182012  27.716546   \n996   1996   278668  8408022938            5  9788408022930  48.000000   \n997   1997   278668  8408044079            5  9788408044079  48.000000   \n998   1998   278668  8423322912            5  9788423322916  48.000000   \n999   1999   278668  8440644965            5  9788440644961  48.000000   \n\n            city       state  country  user_mean  user_count  \\\n0    baton rouge   louisiana      usa        8.0         1.0   \n1    baton rouge   louisiana      usa        8.0         1.0   \n2       edmonton     alberta   canada        8.0         1.0   \n3        zachary   louisiana      usa        5.0         1.0   \n4    baton rouge   louisiana      usa        8.0         1.0   \n..           ...         ...      ...        ...         ...   \n995    arlington       texas      usa        5.8         5.0   \n996       madrid      madrid    spain        5.0         5.0   \n997       madrid      madrid    spain        5.0         5.0   \n998       madrid      madrid    spain        5.0         5.0   \n999       madrid      madrid    spain        5.0         5.0   \n\n     normalized_rating  \n0                  0.0  \n1                  0.0  \n2                  0.0  \n3                  0.0  \n4                  0.0  \n..                 ...  \n995               -2.8  \n996                0.0  \n997                0.0  \n998                0.0  \n999                0.0  \n\n[1000 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>user_id</th>\n      <th>isbn</th>\n      <th>book_rating</th>\n      <th>isbn13</th>\n      <th>age</th>\n      <th>city</th>\n      <th>state</th>\n      <th>country</th>\n      <th>user_mean</th>\n      <th>user_count</th>\n      <th>normalized_rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000</td>\n      <td>277784</td>\n      <td>0440802911</td>\n      <td>8</td>\n      <td>978044080297</td>\n      <td>17.000000</td>\n      <td>baton rouge</td>\n      <td>louisiana</td>\n      <td>usa</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1001</td>\n      <td>277788</td>\n      <td>0440407524</td>\n      <td>8</td>\n      <td>9780440407522</td>\n      <td>17.000000</td>\n      <td>baton rouge</td>\n      <td>louisiana</td>\n      <td>usa</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1002</td>\n      <td>277794</td>\n      <td>0440967694</td>\n      <td>8</td>\n      <td>9780440967699</td>\n      <td>47.843881</td>\n      <td>edmonton</td>\n      <td>alberta</td>\n      <td>canada</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1003</td>\n      <td>277795</td>\n      <td>0064406601</td>\n      <td>5</td>\n      <td>9780064406604</td>\n      <td>17.000000</td>\n      <td>zachary</td>\n      <td>louisiana</td>\n      <td>usa</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1004</td>\n      <td>277797</td>\n      <td>0440228441</td>\n      <td>8</td>\n      <td>9780440228448</td>\n      <td>17.000000</td>\n      <td>baton rouge</td>\n      <td>louisiana</td>\n      <td>usa</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>1995</td>\n      <td>278663</td>\n      <td>0451182014</td>\n      <td>3</td>\n      <td>9780451182012</td>\n      <td>27.716546</td>\n      <td>arlington</td>\n      <td>texas</td>\n      <td>usa</td>\n      <td>5.8</td>\n      <td>5.0</td>\n      <td>-2.8</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>1996</td>\n      <td>278668</td>\n      <td>8408022938</td>\n      <td>5</td>\n      <td>9788408022930</td>\n      <td>48.000000</td>\n      <td>madrid</td>\n      <td>madrid</td>\n      <td>spain</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>1997</td>\n      <td>278668</td>\n      <td>8408044079</td>\n      <td>5</td>\n      <td>9788408044079</td>\n      <td>48.000000</td>\n      <td>madrid</td>\n      <td>madrid</td>\n      <td>spain</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>1998</td>\n      <td>278668</td>\n      <td>8423322912</td>\n      <td>5</td>\n      <td>9788423322916</td>\n      <td>48.000000</td>\n      <td>madrid</td>\n      <td>madrid</td>\n      <td>spain</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>1999</td>\n      <td>278668</td>\n      <td>8440644965</td>\n      <td>5</td>\n      <td>9788440644961</td>\n      <td>48.000000</td>\n      <td>madrid</td>\n      <td>madrid</td>\n      <td>spain</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows Ã— 12 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Features\n",
    "X = df.drop(['user_id', 'isbn13', 'book_rating'], axis=1)\n",
    "# Prediction\n",
    "Y = df['book_rating']\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "            age  country_usa  country_canada  country_united_kingdom  \\\n0     17.000000            0               0                       0   \n1     17.000000            0               0                       0   \n2     47.843881            0               0                       0   \n3     17.000000            0               0                       0   \n4     17.000000            0               0                       0   \n...         ...          ...             ...                     ...   \n1010  27.716546            0               0                       0   \n1011  48.000000            0               0                       0   \n1012  48.000000            0               0                       0   \n1013  48.000000            0               0                       0   \n1014  48.000000            0               0                       0   \n\n      country_germany  country_spain  country_australia  country_italy  \\\n0                   0              0                  0              0   \n1                   0              0                  0              0   \n2                   0              0                  0              0   \n3                   0              0                  0              0   \n4                   0              0                  0              0   \n...               ...            ...                ...            ...   \n1010                0              0                  0              0   \n1011                0              0                  0              0   \n1012                0              0                  0              0   \n1013                0              0                  0              0   \n1014                0              0                  0              0   \n\n      country_france  country_portugal  ...  publisher_silhouette  \\\n0                  0                 0  ...                     0   \n1                  0                 0  ...                     0   \n2                  0                 0  ...                     0   \n3                  0                 0  ...                     0   \n4                  0                 0  ...                     0   \n...              ...               ...  ...                   ...   \n1010               0                 0  ...                     0   \n1011               0                 0  ...                     0   \n1012               0                 0  ...                     0   \n1013               0                 0  ...                     0   \n1014               0                 0  ...                     0   \n\n      publisher_pocket  publisher_ballantine_books  publisher_bantam_books  \\\n0                    0                           0                       0   \n1                    0                           0                       0   \n2                    0                           0                       0   \n3                    0                           0                       0   \n4                    0                           0                       0   \n...                ...                         ...                     ...   \n1010                 0                           0                       0   \n1011                 0                           0                       0   \n1012                 0                           0                       0   \n1013                 0                           0                       0   \n1014                 0                           0                       0   \n\n      publisher_scholastic  publisher_simon_&amp;_schuster  \\\n0                        0                               0   \n1                        0                               0   \n2                        0                               0   \n3                        0                               0   \n4                        0                               0   \n...                    ...                             ...   \n1010                     0                               0   \n1011                     0                               0   \n1012                     0                               0   \n1013                     0                               0   \n1014                     0                               0   \n\n      publisher_penguin_books  publisher_berkley_publishing_group  \\\n0                           0                                   0   \n1                           0                                   0   \n2                           0                                   0   \n3                           0                                   0   \n4                           0                                   0   \n...                       ...                                 ...   \n1010                        0                                   0   \n1011                        0                                   0   \n1012                        0                                   0   \n1013                        0                                   0   \n1014                        0                                   0   \n\n      publisher_warner_books  publisher_other  \n0                          0                1  \n1                          0                1  \n2                          0                1  \n3                          0                1  \n4                          0                1  \n...                      ...              ...  \n1010                       0                1  \n1011                       0                1  \n1012                       0                1  \n1013                       0                1  \n1014                       0                1  \n\n[1015 rows x 35 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>country_usa</th>\n      <th>country_canada</th>\n      <th>country_united_kingdom</th>\n      <th>country_germany</th>\n      <th>country_spain</th>\n      <th>country_australia</th>\n      <th>country_italy</th>\n      <th>country_france</th>\n      <th>country_portugal</th>\n      <th>...</th>\n      <th>publisher_silhouette</th>\n      <th>publisher_pocket</th>\n      <th>publisher_ballantine_books</th>\n      <th>publisher_bantam_books</th>\n      <th>publisher_scholastic</th>\n      <th>publisher_simon_&amp;amp;_schuster</th>\n      <th>publisher_penguin_books</th>\n      <th>publisher_berkley_publishing_group</th>\n      <th>publisher_warner_books</th>\n      <th>publisher_other</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>17.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>17.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>47.843881</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>17.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1010</th>\n      <td>27.716546</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1011</th>\n      <td>48.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1012</th>\n      <td>48.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1013</th>\n      <td>48.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1014</th>\n      <td>48.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>1015 rows Ã— 35 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "0       8\n1       8\n2       8\n3       5\n4       8\n       ..\n1010    3\n1011    5\n1012    5\n1013    5\n1014    5\nName: book_rating, Length: 1015, dtype: int64"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, random_state=7)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the model from the file\n",
    "with open(\"random_forest_classifier5.pkl\", \"rb\") as file:\n",
    "    rfc = pickle.load(file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestClassifier(min_weight_fraction_leaf=0, n_jobs=3, random_state=1)",
      "text/html": "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(min_weight_fraction_leaf=0, n_jobs=3, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(min_weight_fraction_leaf=0, n_jobs=3, random_state=1)</pre></div></div></div></div></div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00         7\n",
      "           4       0.00      0.00      0.00        16\n",
      "           5       0.37      0.26      0.30        39\n",
      "           6       0.19      0.17      0.18        30\n",
      "           7       0.23      0.25      0.24        65\n",
      "           8       0.22      0.28      0.25        69\n",
      "           9       0.20      0.23      0.22        44\n",
      "          10       0.15      0.15      0.15        33\n",
      "\n",
      "    accuracy                           0.21       305\n",
      "   macro avg       0.14      0.13      0.13       305\n",
      "weighted avg       0.21      0.21      0.21       305\n",
      "\n",
      "21.311475409836063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fab/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/fab/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/fab/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "rfc_pred = rfc.predict(X_test)\n",
    "print(classification_report(y_test, rfc_pred))\n",
    "print(accuracy_score(y_test, rfc_pred) * 100)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
