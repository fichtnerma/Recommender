{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use TF IDF Vectoriser to transform text into vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marku\\SoftwareProjects\\Master\\Recommender Project\\bibrec\\server\\Utils.py:35: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path, sep=\";\", encoding=\"latin-1\", index_col=False)\n",
      "C:\\Users\\marku\\AppData\\Local\\Temp\\ipykernel_109628\\3023402671.py:9: DtypeWarning: Columns (15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  book_data = pd.read_csv(\"./data/editions_dump.csv\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import pandas as pd\n",
    "from bibrec.server.Utils import *\n",
    "\n",
    "\n",
    "\n",
    "books = get_books(\"./data/BX-Books.csv\")\n",
    "book_data = pd.read_csv(\"./data/editions_dump.csv\")\n",
    "CHUNK_QUANTITY = 50\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "book_data = pd.DataFrame(book_data).drop_duplicates(subset=[\"isbn_10\"], ignore_index=True)\n",
    "similarities = []\n",
    "mappings = []\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing data to remove unnessecary spaces and characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def book_data_preprocessing():\n",
    "    global book_data\n",
    "    book_data[\"book_info\"] = book_data[\"book_info\"].astype(\"string\")\n",
    "    book_data[\"book_info\"] = book_data[\"book_info\"].apply(lambda x: x.lower())\n",
    "    book_data[\"book_info\"] = book_data[\"book_info\"].apply(lambda x: x.replace(\"(\", ''))\n",
    "    book_data[\"book_info\"] = book_data[\"book_info\"].apply(lambda x: x.replace(\")\", ''))\n",
    "    book_data[\"book_info\"] = book_data[\"book_info\"].apply(lambda x: x.replace(',', ''))\n",
    "    book_data[\"book_info\"] = book_data[\"book_info\"].apply(lambda x: x.replace('.', ''))\n",
    "    book_data[\"book_info\"] = book_data[\"book_info\"].apply(lambda x: x.replace(\"'\", ''))\n",
    "    book_data[\"book_info\"] = book_data[\"book_info\"].apply(lambda x: x.replace(\"--\", ''))\n",
    "    book_data[\"book_info\"] = book_data[\"book_info\"].apply(lambda x: x.replace(\"  \", ' '))\n",
    "    book_data[\"book_info\"] = book_data[\"book_info\"].apply(lambda x: ' '.join(list(set(x.split()))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Similarity Matrix for all books using cosine similarity\n",
    "\n",
    "In order to avoid running out of memory while calculating the Matrix we decided to split the data into smaller chunks\n",
    "- This has the effect that only similarities for books in the same chunk are calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarities():\n",
    "    global similarities\n",
    "    global mappings\n",
    "    global book_data\n",
    "    # data cleaning\n",
    "    book_data.rename(columns={'isbn_10': 'isbn', 'first_sentence.value': 'first_sentence', 'notes.value': 'notes'}, inplace=True)\n",
    "    book_data.isbn = book_data.isbn.map(lambda x: str(x).strip()[2:-2])\n",
    "    book_data = books.merge(book_data, on=\"isbn\", how=\"inner\")\n",
    "    book_data = book_data.drop(columns=[\"Unnamed: 0\", \"isbn_13\", \"publishers\", \"title\", \"first_sentence.type\", \"notes.type\"])\n",
    "    book_data.subjects = book_data.subjects.map(lambda x: str(x).strip()[2:-2])\n",
    "    book_data.genres = book_data.genres.map(lambda x: str(x).strip()[2:-2])\n",
    "    book_data = book_data.fillna(\" \")\n",
    "\n",
    "    # add book_info column and append relevant data\n",
    "    book_data[\"book_info\"] = book_data[\"book_title\"] + \" \" + book_data[\"subjects\"] + \" \" + book_data[\"genres\"]\n",
    "    book_data_preprocessing()\n",
    "\n",
    "    similarities = []\n",
    "    mappings = []\n",
    "    for i in range(0, CHUNK_QUANTITY):\n",
    "        len_books = book_data.shape[0] / CHUNK_QUANTITY\n",
    "        chunk_data = book_data[int(i * len_books):int((i + 1) * len_books)]\n",
    "        chunk_data = chunk_data.reset_index(drop=True)\n",
    "        similarity_matrix = get_similarity_matrix(chunk_data)\n",
    "        similarities.append(similarity_matrix)\n",
    "        mappings.append(pd.Series(chunk_data.index, index=chunk_data[\"isbn13\"]))\n",
    "\n",
    "def get_similarity_matrix(book_data):\n",
    "    tfidf_matrix = tfidf.fit_transform(book_data[\"book_info\"])\n",
    "    similarity_matrix = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "    return similarity_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All similar items are gathered for the given isbn and sorted in a descending order.\n",
    "The number of returned items is split at n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_tf_idf(isbn13, n=15):\n",
    "    global similarities\n",
    "    global mappings\n",
    "    global book_data\n",
    "    book_indices = []\n",
    "    for i in range(0, CHUNK_QUANTITY):\n",
    "        if isbn13 in mappings[i].index:\n",
    "            similarity_matrix = similarities[i]\n",
    "            book_index = mappings[i][isbn13]\n",
    "\n",
    "            if isinstance(book_index, pd.Series):\n",
    "                book_index = book_index[0]\n",
    "            similarity_score = list(enumerate(similarity_matrix[book_index]))\n",
    "            # Sort the books based on the similarity scores\n",
    "            similarity_score = sorted(similarity_score, key=lambda x: x[1], reverse=True)\n",
    "            similarity_score = similarity_score[1:n + 1]\n",
    "\n",
    "            # Check if all similarities are 0\n",
    "            if all(i[1] == 0 for i in similarity_score):\n",
    "                return None\n",
    "\n",
    "            book_indices.append([i[0] for i in similarity_score])\n",
    "\n",
    "    if len(book_indices) == 0:\n",
    "        return None\n",
    "    return book_data[[\"book_title\", \"isbn13\", \"isbn\"]].iloc[book_indices[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             book_title         isbn13  \\\n",
      "3648                             Perdido Street Station  9780345443021   \n",
      "4002  The Arabian Nights: More Marvels and Wonders o...  9780451527493   \n",
      "4003  Arabian Nights: The Marvels and Wonders of the...  9780451525420   \n",
      "2635                           Night's Pawn (Shadowrun)  9780451452382   \n",
      "4292                       On the Street Where You Live  9780671004538   \n",
      "45                                    The Street Lawyer  9780440225706   \n",
      "2736                                      Eureka Street  9782264027757   \n",
      "2871    Scarabian Nights:Sabrina, The Teenage Witch #24  9780671028046   \n",
      "502                                   The Street Lawyer  9780385490993   \n",
      "3610                           The Cater Street Hangman  9780449208670   \n",
      "2226  On Basilisk Station (Honor Harrington Series, ...  9780671577728   \n",
      "523                               Her Mother's Daughter  9780345353627   \n",
      "2645                           The Third Witch: A Novel  9780743417723   \n",
      "3396                               After Lucy : A Novel  9780060959425   \n",
      "1900                                  The Street Lawyer  9780099244929   \n",
      "\n",
      "            isbn  \n",
      "3648  0345443020  \n",
      "4002  0451527496  \n",
      "4003  0451525426  \n",
      "2635  0451452380  \n",
      "4292  0671004530  \n",
      "45    0440225701  \n",
      "2736  2264027754  \n",
      "2871  0671028049  \n",
      "502   0385490992  \n",
      "3610  0449208672  \n",
      "2226  0671577727  \n",
      "523   0345353625  \n",
      "2645  0743417720  \n",
      "3396  0060959428  \n",
      "1900  0099244926  \n"
     ]
    }
   ],
   "source": [
    "calculate_similarities()\n",
    "print(recommend_tf_idf(\"9780771074677\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b9a40f058525f2d65f9906156bda6efa59e0d787a10d236efb1510ab56f2f48e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
