{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline - Most popular\n",
    "Most popular books are the top most rated books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johannes/Studium/MMT/1. Semester/Fächer/Recommender Systems/Abschlussprojekt/code/recommender-systems/bibrec/server/Utils.py:16: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path, sep=\";\", encoding=\"latin-1\")\n",
      "/Users/johannes/Studium/MMT/1. Semester/Fächer/Recommender Systems/Abschlussprojekt/code/recommender-systems/bibrec/server/Utils.py:98: FutureWarning: In a future version of pandas all arguments of StringMethods.split except for the argument 'pat' will be keyword-only.\n",
      "  location_seperated = users.location.str.split(',', 2, expand=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Ratings Count: 383962\n"
     ]
    }
   ],
   "source": [
    "from bibrec.server.Utils import assign_popular_based_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bibrec.server.evaluation as eval\n",
    "from collections import defaultdict\n",
    "import bibrec.server.Utils as Utils\n",
    "import importlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "importlib.reload(eval)\n",
    "importlib.reload(Utils)\n",
    "\n",
    "books, users, ratings = Utils.get_normalized_data()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Splitting the Data\n",
    "In [the Notebook File baseline3](notebooks/baseline3.ipynb), the splitting into training/testing data was done on a per-user basis.\n",
    "It was found that this only minimally increases the recall and precision of the baseline.\n",
    "Due to performance reasons, we reverted back to a normal train/test split.\n",
    "normal splitting since user specific splitting doesn't make that much of a difference and takes a long time\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [
    "train, test = train_test_split(ratings, test_size=0.25)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**The split was also tested with 0.2 and 0.3**\n",
    "- 0.2 - Precision 0.00133 and Recall 0.02313\n",
    "- 0.3 - Precision 0.00149 and Recall 0.0219"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Ratings Count: 383962\n",
      "Train Data Ratings Count: 287971\n",
      "Test Data Ratings Count: 95991\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Ratings Count:\", len(ratings))\n",
    "print(\"Train Data Ratings Count:\", len(train))\n",
    "print(\"Test Data Ratings Count:\", len(test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [],
   "source": [
    "book_ratings_dict = {\n",
    "    'user_id': train['user_id'].values,\n",
    "    'isbn13': train['isbn13'].values,\n",
    "    'book_rating': train['book_rating'].values\n",
    "}\n",
    "\n",
    "book_rating_df = train[['user_id', 'isbn13', 'book_rating']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most popular books are:\n",
      "              isbn13  vote_count  avg_rating  weighted_rating\n",
      "9169   9780316666343         545    8.174312         8.171968\n",
      "33511  9780971880108         441    4.414966         4.429044\n",
      "14316  9780385504201         368    8.375000         8.370450\n",
      "8036   9780312195519         287    8.177700         8.173241\n",
      "4652   9780060928339         248    7.814516         7.812266\n",
      "23536  9780590353427         224    8.919643         8.907374\n",
      "7088   9780142001745         223    8.434978         8.426963\n",
      "1757    978044667227         216    8.083333         8.078287\n",
      "20395  9780452282155         212    7.985849         7.981620\n",
      "9150   9780316601955         210    7.561905         7.561635\n",
      "24734  9780671027360         207    8.120773         8.115151\n",
      "17047  9780440237228         193    7.378238         7.379829\n",
      "26815  9780679764021         191    7.701571         7.699827\n",
      "29813  9780786868711         187    7.909091         7.905114\n",
      "8212   9780312278588         174    7.655172         7.653787\n",
      "17703  9780446310789         171    8.953216         8.936801\n",
      "9209   9780316769488         171    7.543860         7.543737\n",
      "28438  9780743418171         170    7.994118         7.988759\n",
      "4687   9780060930530         169    8.171598         8.164132\n",
      "7361   9780156027328         167    8.005988         8.000394\n"
     ]
    }
   ],
   "source": [
    "train[\"isbn13\"] = train[\"isbn13\"].astype(\"int\")\n",
    "books[\"isbn13\"] = books[\"isbn13\"].astype(\"int\")\n",
    "popular_books = assign_popular_based_score(train, books, \"user_id\", \"isbn13\", \"book_rating\")\n",
    "popular_books = popular_books.sort_values(\"vote_count\", ascending=False)\n",
    "\n",
    "print(\"Most popular books are:\")\n",
    "print(popular_books[:20])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "pop_dict = {\n",
    "    'item_id': popular_books['isbn13'].values,\n",
    "    'est_r': popular_books['avg_rating'].values,\n",
    "}\n",
    "\n",
    "pop_df = pd.DataFrame.from_dict(pop_dict)\n",
    "\n",
    "ratings_dict = {\n",
    "    'user_id': test['user_id'].values,\n",
    "    'item_id': test['isbn13'].values,\n",
    "    'rating': test['book_rating'].values\n",
    "}\n",
    "\n",
    "ratings_df = pd.DataFrame.from_dict(ratings_dict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Count: 29838\n"
     ]
    }
   ],
   "source": [
    "test_uids = ratings_df[\"user_id\"].unique()\n",
    "\n",
    "print(\"User Count:\", len(test_uids))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "def def_value():\n",
    "    return \"Not Present\"\n",
    "\n",
    "top_n = defaultdict(def_value)\n",
    "for uid in test_uids:\n",
    "    top_n[uid] = pop_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision: 0.0009564055357524559\n",
      "--- Calculation time: 60.37415409088135 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "avg_precision = eval.get_avg_precision(ratings_df, top_n, k=50)\n",
    "\n",
    "print(\"Average Precision:\", avg_precision)\n",
    "print(\"--- Calculation time: %s seconds ---\" % (time.time() - start_time))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Recall: 0.05060547583164393\n",
      "--- Calculation time: 126.55736088752747 seconds ---\n"
     ]
    }
   ],
   "source": [
    "avg_recall = eval.get_avg_recall(ratings_df, top_n, k=50)\n",
    "\n",
    "print(\"Average Recall:\", avg_recall)\n",
    "print(\"--- Calculation time: %s seconds ---\" % (time.time() - start_time))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Precision and Recall has also been calculated with different k's:**\n",
    "- k=25: Precision 0.00169 and Recall 0.01567\n",
    "- k=50: Precision 0.00143 and Recall 0.02329\n",
    "- k=75: Precision 0.00124 and Recall 0.02944\n",
    "- k=100: Precision 0.00124 and Recall 0.03518\n",
    "- k=200: Precision 0.00096 and Recall 0.05061"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
